{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML Project Assignment.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1DmqgZJTnEziIp0ekGlRC19rISNz75NWq",
          "timestamp": 1530117213755
        },
        {
          "file_id": "1UrWLlxrCNXxAocRdf7ktJ96OQO9GepzS",
          "timestamp": 1530075309550
        },
        {
          "file_id": "1pfGE5rX3dz6Xuz24Nq-EoVjyG3G8Rgcq",
          "timestamp": 1529935695601
        },
        {
          "file_id": "1smA7V_jFgej50GtWscJz_hE1BH-iCpdj",
          "timestamp": 1529883984655
        },
        {
          "file_id": "14-ikqVBuAnePr8RJz6lERUqXYtas8zX9",
          "timestamp": 1529802169116
        },
        {
          "file_id": "1DfwquLAXV9tX_7U4a9PBzQVHogArCza_",
          "timestamp": 1529695626260
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FYbXz8ZO23fN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Project Assignment:** In this project assignment, you will go through the process of creating a MS Azure Machine Learning pipeline for a couple of different scenarios. In the first question, you will be asked to predict the prices of homes and in the second example, you will be asked to cluster some call center related data."
      ]
    },
    {
      "metadata": {
        "id": "lhHbstZSZF53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 1**: We will work with a dataset that contains real estate related information  i.e. RE_train.  In addition, there is a data description file that provides information on the different columns that constitute the dataset. The ask is to predict the sales price.\n",
        "\n",
        "**Note**: There are quite a few features within the dataset\n",
        "\n",
        "**1)** Read in the RE_train dataset\n",
        "\n",
        "**2)** Select only the columns that will be utilized for model creation\n",
        "\n",
        "**3)** Specify the features that you would like to treat as categorical variables\n",
        "\n",
        "**4)** Specify the features that you would like to treat as numeric features/variables\n",
        "\n",
        "**5) ** Include data/time related features\n",
        "\n",
        "**6)** Specify the label (i.e. the variable that will be predicted)\n",
        "\n",
        "**7) **Split the underlying dataset for training/testing purposes. 75% of the underlying dataset will constitute the training dataset and 25% of the underlying dataset will constitute the test dataset\n",
        "\n",
        "**8) **Once the data is split, train a model. In this case since we are dealing with predicting prices, choose an appropriate model that should be trained\n",
        "\n",
        "**9) **Once the training is completed, score/test the model with the test dataset. Visualize the output that you get from \"Scoring\" the model. Scroll to the right of the visualization and you will notice that a new column has been added (i.e. prediction for the sales price)\n",
        "\n",
        "**10)** Evaluate the accuracy of the predictions and summarize your findings\n",
        "\n",
        "\n",
        "**Datasets: ** \n",
        "\n",
        "**RE_Train:** https://www.dropbox.com/s/5pyl2duwz483i5n/RE_train.csv?raw=1\n",
        "\n",
        "**RE_Description:** https://www.dropbox.com/s/w6641kbej3suc0n/RE_description.txt?raw=1"
      ]
    },
    {
      "metadata": {
        "id": "lHERmsnYS2FZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q1.PNG)\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q1-score.PNG)\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q1-eval.PNG)"
      ]
    },
    {
      "metadata": {
        "id": "QiyHRX1TgCrA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2: **  The call center dataset contains information on the ** '# of months of experience'** and the **'# of calls attended'**. The objective is to group similar records into **4 **buckets so that details such as the average # of calls placed along with the associated average months of experience for each cluster can be easily gleaned.\n",
        "\n",
        "\n",
        "**1)** Read in the  dataset\n",
        "\n",
        "**2)** Train a **K-Means** clustering model\n",
        "\n",
        "**3)** Select the relevant columns for analysis purposes\n",
        "\n",
        "**4)** Split the output into distinct assignment buckets so that you can visualize the average # of calls placed along with the associated average months of experience for the respective cluster. Summarize your findings\n",
        "\n",
        "***Hint:*** Use 4 \"**Split data**\" operators in order to visualize the data in each cluster\n",
        "\n",
        "**5) ** Instead of using 4 \"**Split data**\" operators, split the underlying data set into training (70%)/test (30%) dataset. Assign the data into clusters by using the \"**Assign Data to Clusters**\" operator. \n",
        "\n",
        "**6)** Use the \"**Evaluate Model**\" operator to output the cluster assignment results. Summarize your findings\n",
        "\n",
        "\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "**Call center data**: https://www.dropbox.com/s/t5rmdjve9dwey8o/Callcenter.csv?raw=1"
      ]
    },
    {
      "metadata": {
        "id": "mT7DiAjyTBtu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2.PNG)\n",
        "\n",
        "### Cluster 1\n",
        "**Calls**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster0-calls.PNG)\n",
        "\n",
        "**Experience**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster0-experience.PNG)\n",
        "\n",
        "### Cluster 2\n",
        "**Calls**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster1-calls.PNG)\n",
        "\n",
        "**Experience**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster1-experience.PNG)\n",
        "\n",
        "### Cluster 3\n",
        "**Calls**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster2-calls.PNG)\n",
        "\n",
        "**Experience**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster2-experience.PNG)\n",
        "\n",
        "### Cluster 4\n",
        "**Calls**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster3-calls.PNG)\n",
        "\n",
        "**Experience**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-cluster3-experience.PNG)\n",
        "\n",
        "### Model Evaluation \n",
        "\n",
        "**Test Data**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-test-eval.PNG)\n",
        "\n",
        "**Training Data**\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-train-eval.PNG)"
      ]
    },
    {
      "metadata": {
        "id": "-gq_YtHkTrzZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 3: ** In this question, you will have to insert a Python Script to do the following:\n",
        "\n",
        "Massage/Pre-process the \"**Book Review from Amazon**\" dataset. \n",
        "\n",
        "**a) **Remove special characters\n",
        "\n",
        "**b)** Normalize to lower case\n",
        "\n",
        "**c)** You will need to eliminate punctuations\n",
        "\n",
        "**d)** You will have to deal with/remove stopwords\n",
        "\n",
        "**e)** Tokenize the text\n",
        "\n",
        "**f)** Stem or Lemmatize the text\n",
        "\n",
        "You could also also the \"Preprocess Text\" operator to perform some of the tasks mention above\n",
        "\n",
        "**Dataset:** \"\"**Book Review from Amazon**\"\" which is available as part of the \"Sample\" datasets\n",
        "\n",
        "**Reference:** https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/preprocess-text"
      ]
    },
    {
      "metadata": {
        "id": "KfTfLj_3ealq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q3.PNG)\n",
        "\n",
        "![](https://raw.githubusercontent.com/rayheberer/LambdaSchoolDataScience/master/img/Week%2013/Q2-results.PNG)\n",
        "\n",
        "\n",
        "```\n",
        "# The script MUST contain a function named azureml_main\n",
        "# which is the entry point for this module.\n",
        "\n",
        "# imports up here can be used to \n",
        "import pandas as pd\n",
        "\n",
        "# The entry point function can contain up to two input arguments:\n",
        "#   Param<dataframe1>: a pandas.DataFrame\n",
        "#   Param<dataframe2>: a pandas.DataFrame\n",
        "def azureml_main(dataframe1 = None, dataframe2 = None):\n",
        "\n",
        "    # Execution logic goes here\n",
        "    print('Input pandas.DataFrame #1:\\r\\n\\r\\n{0}'.format(dataframe1))\n",
        "\n",
        "    # If a zip file is connected to the third input port is connected,\n",
        "    # it is unzipped under \".\\Script Bundle\". This directory is added\n",
        "    # to sys.path. Therefore, if your zip file contains a Python file\n",
        "    # mymodule.py you can import it using:\n",
        "    # import mymodule\n",
        "    dataframe1['Preprocessed Col2'] = dataframe1['Preprocessed Col2'].apply(remove_punct)\n",
        "    # Return value must be of a sequence of pandas.DataFrame\n",
        "    return dataframe1,\n",
        "\n",
        "def remove_punct(text):\n",
        "    \"\"\"Bye Bye punctuation\"\"\"\n",
        "    for char in set(text):\n",
        "        if not (char.isalpha() or char==' '):\n",
        "            text = text.replace(char, '')\n",
        "            \n",
        "\n",
        "    return text\n",
        "```"
      ]
    }
  ]
}