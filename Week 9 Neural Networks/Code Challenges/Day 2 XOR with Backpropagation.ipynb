{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XOR with one hidden layer.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1KUs_vl8IjIoJyFJMLBhaC9uuaZTLpopp",
          "timestamp": 1527693617364
        },
        {
          "file_id": "1sGWYbVhGqLU_2-QkD67UZX47mikSGYTk",
          "timestamp": 1527691893929
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "4jXHmKiJEQI8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# LAMBDA SCHOOL\n",
        "#\n",
        "# MACHINE LEARNING\n",
        "#\n",
        "# MIT LICENSE\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-75eysIEEnfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this challenge we build that single-hidden-layer neural network that we discussed yesterday. Like yesterday, it shoud have two numbers (call them x1 and x2) in the input layer, two (y1 and y2) in the hidden layer, one one output (z). It also has a total of nine weights. Call them a, b, c, d, e, f, g, h, i so that\n",
        "\n",
        "y1 = sigma(a*x1 + b*x2 + c)\n",
        "\n",
        "and\n",
        "\n",
        "y2 = sigma(d*x1 + e*x2 + f)\n",
        "\n",
        "and\n",
        "\n",
        "z = sigma(g*y1 + h*y2 + i)"
      ]
    },
    {
      "metadata": {
        "id": "YnDndQTsGHFf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Make sure you undrestand why this corresponds to the neural net diagram you saw yesterday! And notice that the output is no longer rounded. The reasons for this are easier to explain face to face, but it has to do with the fact that there are two stages to using a machine model: first is the *testing* phase, where you try it on the data you already have answers for. Once you've optimized that comes the *application* phase, where you use it to predict the outputs for novel inputs. The short version of our story is that we round at the last step during the application phase, but not during the testing phase. If this seems silly, don't let it stress you out too much for now.\n",
        "\n",
        "The first thing to do is to initialize the values of a through f randomly, asembling them into the numpy vector [a, b, c, d, e, f, g, h, i]. Use numpy's random function with 42 as your seed (if you don't know what this means, get to Googling). So your results match your classmates', use the usual numpy random vector method described here: \n",
        "\n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html"
      ]
    },
    {
      "metadata": {
        "id": "I7LezcI9F9Mn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "weights = np.random.normal(scale=0.1, size=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9S_wBIyHNp8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great. Now define a function NN(x1, x2) that takes in x1 and x2 and spits out z as described above. You'll probably find it helps to define the sigmoid function first."
      ]
    },
    {
      "metadata": {
        "id": "cImxaTrVGyQh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sigma(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def NN(x1, x2):\n",
        "    y1 = sigma(weights[0]*x1 + weights[1]*x2 + weights[2])\n",
        "    y2 = sigma(weights[3]*x1 + weights[4]*x2 + weights[5])\n",
        "    \n",
        "    z = sigma(weights[6]*y1 + weights[7]*y2 + weights[8])\n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uo7ES-gTH_hn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now think back to the SSE we used to measure how we a linear model performed. We can do the same thing here! We're trying to model XOR, so our set of desired inputs and outputs is:\n",
        "\n",
        "NN(0,0) == 0\n",
        "\n",
        "NN(0,1) == 1\n",
        "\n",
        "NN(1,0) == 1\n",
        "\n",
        "NN(1,1) == 0\n",
        "\n",
        "To evaluate the SSE, we plug each of these inputs into our NN function, compute the squared difference between that result and the intended results listed just above, and add up those four squared errors. The next step for you is to define that squared error function! Since we have a through f defined above it shouldn't use them as literal function arguments, but they should appear inside the definition of SS. It may be helpful to define an actual XOR function first."
      ]
    },
    {
      "metadata": {
        "id": "ltA5bi3mHeL7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def XOR(x, y):\n",
        "    if x == y:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def SSE():\n",
        "    X = [(0,0), (0,1), (1,0), (1,1)]\n",
        "    \n",
        "    sse = 0\n",
        "    for x1, x2 in X:\n",
        "        y = XOR(x1, x2)\n",
        "        yhat = NN(x1, x2)\n",
        "        sse += (y-yhat)**2\n",
        "        \n",
        "    return sse\n",
        "\n",
        "def accuracy():\n",
        "    X = [(0,0), (0,1), (1,0), (1,1)]\n",
        "    \n",
        "    correct = 0\n",
        "    for x1, x2 in X:\n",
        "        y = XOR(x1, x2)\n",
        "        yhat = NN(x1, x2)\n",
        "        correct += int(np.round(yhat)==y)\n",
        "        \n",
        "    return correct / len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvI3cxdQK6ED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we try out the same character-building exercise we did when we first tried out linear regression:\n",
        "\n",
        "By any means necessary (fiddling by hand, gradient descent, discussion with your classmates), find values of a, ..., f that make the SSE as small as possible. Note that, depending on how you approach this, our earlier step of initializing the values randomly may or not have been necessary"
      ]
    },
    {
      "metadata": {
        "id": "6x0SMSZUHfS8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def optimize(weights, lr=0.01, epochs=100):\n",
        "    X = [(0,0), (0,1), (1,0), (1,1)]\n",
        "    \n",
        "    for _ in range(epochs):\n",
        "        for x1, x2 in X:\n",
        "            y = XOR(x1, x2)\n",
        "\n",
        "            a11 = sigma(weights[0]*x1 + weights[1]*x2 + weights[2])\n",
        "            a12 = sigma(weights[3]*x1 + weights[4]*x2 + weights[5])\n",
        "\n",
        "            a2 = sigma(weights[6]*a11 + weights[7]*a12 + weights[8])\n",
        "            \n",
        "            # delta error with respect to output activation\n",
        "            da2 = a2 - y\n",
        "            # delta output activation with respect to output layer input\n",
        "            dz2 = a2 * (1-a2)\n",
        "            \n",
        "            dout = da2 * dz2\n",
        "            # delta output layer input with respect to bias, weight7, weight6\n",
        "            dw8 = dout\n",
        "            dw7 = dout * a12\n",
        "            dw6 = dout * a11\n",
        "\n",
        "            # delta hidden activations with respect to hidden node inputs\n",
        "            dz12 = a12 * (1-a12)\n",
        "            dz11 = a11 * (1-a11)\n",
        "            \n",
        "            # delta error with respect to bias, weight4, weight3\n",
        "            dw5 = weights[7] * dout * dz12\n",
        "            dw4 = weights[7] * dout * dz12 * x2\n",
        "            dw3 = weights[7] * dout * dz12 * x1\n",
        "            \n",
        "            # delta error with respect to bias, weights1, weights0\n",
        "            dw2 = weights[6] * dout * dz11\n",
        "            dw1 = weights[6] * dout * dz11 * x2\n",
        "            dw0 = weights[6] * dout * dz11 * x1\n",
        "            \n",
        "            deltas = [dw0, dw1, dw2, dw3, dw4, dw5, dw6, dw7, dw8]\n",
        "            for ix, dw in enumerate(deltas):\n",
        "                weights[ix] = weights[ix] - lr*dw\n",
        "                \n",
        "        if SSE() < 0.1:\n",
        "            break\n",
        "            \n",
        "    return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gj21xder7cPR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4cb319d6-ac99-4a70-8392-b043e0774847",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527702972385,
          "user_tz": 420,
          "elapsed": 440,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "weights = np.random.normal(scale=0.5, size=9)\n",
        "print(weights, '\\n')\n",
        "print([NN(0,0), NN(0,1), NN(1,0), NN(1,1)])\n",
        "\n",
        "print('SSE:', SSE())\n",
        "print('Accuracy:', accuracy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.24835708 -0.06913215  0.32384427  0.76151493 -0.11707669 -0.11706848\n",
            "  0.78960641  0.38371736 -0.23473719] \n",
            "\n",
            "[0.5996679303344842, 0.5937707990575999, 0.6275360701458144, 0.6221392298966929]\n",
            "SSE: 1.0504103907888185\n",
            "Accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G9SYR7tTL3f7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "weights = optimize(weights, epochs=200000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4HnkWJtzhUd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c0126773-716b-4981-db45-915f29245e0e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527702990691,
          "user_tz": 420,
          "elapsed": 465,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(weights, '\\n')\n",
        "print([NN(0,0), NN(0,1), NN(1,0), NN(1,1)])\n",
        "\n",
        "print('SSE:', SSE())\n",
        "print('Accuracy:', accuracy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 5.07464927  4.95735308 -1.74895479  2.6981281   2.67841262 -4.03023374\n",
            "  5.67154587 -5.82934728 -2.55137326] \n",
            "\n",
            "[0.14030624828793162, 0.8457269802303404, 0.8463343803367845, 0.18138461724134622]\n",
            "SSE: 0.09999950997575413\n",
            "Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}