{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Coding Challenge #1 Exploring.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1Sl_68o56vaHnGM8v8w46bIYTjLQqyBMj",
          "timestamp": 1528729430628
        },
        {
          "file_id": "1sIBdz6SOq22toKGnIXG_pS7RGlXhVD9K",
          "timestamp": 1528401611325
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "qd1ltfV8QShV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Coding Challenge #1: Natural Language Processing"
      ]
    },
    {
      "metadata": {
        "id": "iWWDecybQ1zz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this Coding Challenge, you will be exposed to the steps needed to get data organized for modelling purposes. You will be exposed to a range of NLP related concepts such as **a)** Tokenization, **b)** Stopwords, **c)** Stemming/Lemmatization, and **d)** Vectorization. \n",
        "\n",
        "Walking through this challenge will equip you with the necessay knowledge to work through the first part of the Project Assignment.\n",
        "\n",
        "**Dataset**: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SWbWGRycQuqh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 1**: Explore the dataset to ascertain the following:\n",
        "\n",
        "**a)** Determine whether there are any missing values. If missing values are diagnosed, treat them. \n",
        "\n",
        "**b)** Ascertain the breakdown/count of messages. 1) How many \"Spam\" messages are there and 2) How many \"Ham\" messages are there?"
      ]
    },
    {
      "metadata": {
        "id": "1FPgU08dVPsc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "5dafe13f-1319-4ec8-d4e7-f371a008be33",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733322459,
          "user_tz": 420,
          "elapsed": 4697,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Step 1\n",
        "# Get the data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip -o smsspamcollection.zip\n",
        "!head SMSSpamCollection"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-11 16:08:39--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203415 (199K) [application/zip]\n",
            "Saving to: ‘smsspamcollection.zip.1’\n",
            "\n",
            "smsspamcollection.z 100%[===================>] 198.65K   432KB/s    in 0.5s    \n",
            "\n",
            "2018-06-11 16:08:40 (432 KB/s) - ‘smsspamcollection.zip.1’ saved [203415/203415]\n",
            "\n",
            "Archive:  smsspamcollection.zip\n",
            "  inflating: SMSSpamCollection       \n",
            "  inflating: readme                  \n",
            "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "ham\tOk lar... Joking wif u oni...\n",
            "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "ham\tU dun say so early hor... U c already then say...\n",
            "ham\tNah I don't think he goes to usf, he lives around here though\n",
            "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
            "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
            "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
            "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
            "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EXZg54ffLfNW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "2717a4a4-49cb-4bce-acad-b80ccb6d4608",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733322909,
          "user_tz": 420,
          "elapsed": 377,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Read with pandas\n",
        "import pandas as pd\n",
        "sms_data = pd.read_table('./SMSSpamCollection', header=None,\n",
        "                         names=['category', 'content'])\n",
        "sms_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                            content\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "k-3NrhmeXSuH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35016f31-adc7-4c17-8b44-e9139b90ea7a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733324262,
          "user_tz": 420,
          "elapsed": 576,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('Any Missing Values:', sms_data.isnull().any().any())\n",
        "counts = sms_data.groupby('category').count()\n",
        "print('ham messages: {}, spam messages: {}'.format(counts.loc['ham'].values[0],\n",
        "                                                   counts.loc['spam'].values[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Any Missing Values: False\n",
            "ham messages: 4825, spam messages: 747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g7800z1HVSs-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 2: **Massage/Pre-process the dataset:\n",
        "\n",
        "**a)** You will need to eliminate punctuations\n",
        "\n",
        "**b)** You will have to deal with/remove stopwords\n",
        "\n",
        "**c)** Tokenize the text\n",
        "\n",
        "**d)** Stem or Lemmatize the text"
      ]
    },
    {
      "metadata": {
        "id": "-eE-T4d_ZwpR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoyxWrzIdGDK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "69101aee-92ad-4aeb-91be-79b09467a103",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733327100,
          "user_tz": 420,
          "elapsed": 547,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyEJgKpGeZxS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def process_text(sentence):\n",
        "    # tokenize\n",
        "    sentence = nltk.word_tokenize(sentence)\n",
        "    \n",
        "    # remove stop words and punctuation, lemmatize\n",
        "    sentence = [wnl.lemmatize(w) for w in sentence \n",
        "                if w not in stop_words and w.isalpha()]\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YyKrH1Hxewvq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "7f3850b8-b625-4f17-db4a-b0082af8f944",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733333276,
          "user_tz": 420,
          "elapsed": 4615,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "tokenized = sms_data.copy()\n",
        "tokenized['content'] = sms_data['content'].apply(process_text)\n",
        "tokenized.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>[Go, jurong, point, Available, bugis, n, great...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>[Free, entry, wkly, comp, win, FA, Cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>[Nah, I, think, go, usf, life, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                            content\n",
              "0      ham  [Go, jurong, point, Available, bugis, n, great...\n",
              "1      ham                     [Ok, lar, Joking, wif, u, oni]\n",
              "2     spam  [Free, entry, wkly, comp, win, FA, Cup, final,...\n",
              "3      ham      [U, dun, say, early, hor, U, c, already, say]\n",
              "4      ham     [Nah, I, think, go, usf, life, around, though]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "IfBGUVCKXz7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Perform Vectorization - you will apply 3 different vectorization techniques. Each technique will generate similar document term matrices where the rows of the matrix will represent the respective text messages and the columns will represent each word or a combination of words. Note that the biggest difference between the techniques is the value depicted in the actual cells of the matrix. \n",
        "\n",
        "**1)** Create a document term matrix based on the count of the words in the document. You may want to restrict the # of features/columns based on the top most features ordered by term frequency across the document\n",
        "\n",
        "**2)** Create a trigram vector using a combination of adjacent words. In this case, n=3\n",
        "\n",
        "**3) ** Create a TF-IDF vector wherein the cells of the matrix contain values (i.e. weights) to depict how important a word is to an individual SMS message\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sReca_9Sfroy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZsUwMA7hjF39",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "d5d9f883-c728-4188-b086-ad8a2fafbcb9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733335142,
          "user_tz": 420,
          "elapsed": 625,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = [' '.join(sentence) for sentence in tokenized['content']]\n",
        "corpus[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Go jurong point Available bugis n great world la e buffet Cine got amore wat',\n",
              " 'Ok lar Joking wif u oni',\n",
              " 'Free entry wkly comp win FA Cup final tkts May Text FA receive entry question std txt rate T C apply',\n",
              " 'U dun say early hor U c already say',\n",
              " 'Nah I think go usf life around though']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "TLKFOZMdllAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Document Term Matrix"
      ]
    },
    {
      "metadata": {
        "id": "b4-rWA78mcsB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "max_features = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_x0R8EGfjXlW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "806811bb-24d4-4385-f225-ce529e891679",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733379963,
          "user_tz": 420,
          "elapsed": 552,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=max_features)\n",
        "vectorizer.fit(corpus)\n",
        "document_term_matrix = vectorizer.transform(corpus)\n",
        "document_term_matrix.todense()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "NOpFKJkUl16Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sparse_to_dataframe(vectorizer, matrix):\n",
        "    vocab = vectorizer.vocabulary_\n",
        "    columns = [' ' for _ in range(len(vocab))]\n",
        "    for word, number in vocab.items():\n",
        "        columns[number] = word\n",
        "\n",
        "    df = pd.DataFrame(matrix.todense(), columns=columns)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vV7yOEY1kNFm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "8fe68872-a1ef-481a-897a-f3bac620fb36",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733381785,
          "user_tz": 420,
          "elapsed": 417,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "term_frequency = sparse_to_dataframe(vectorizer, document_term_matrix)\n",
        "term_frequency.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>already</th>\n",
              "      <th>amp</th>\n",
              "      <th>and</th>\n",
              "      <th>are</th>\n",
              "      <th>ask</th>\n",
              "      <th>back</th>\n",
              "      <th>but</th>\n",
              "      <th>call</th>\n",
              "      <th>can</th>\n",
              "      <th>claim</th>\n",
              "      <th>...</th>\n",
              "      <th>way</th>\n",
              "      <th>we</th>\n",
              "      <th>week</th>\n",
              "      <th>well</th>\n",
              "      <th>what</th>\n",
              "      <th>work</th>\n",
              "      <th>yeah</th>\n",
              "      <th>yes</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   already  amp  and  are  ask  back  but  call  can  claim  ...   way  we  \\\n",
              "0        0    0    0    0    0     0    0     0    0      0  ...     0   0   \n",
              "1        0    0    0    0    0     0    0     0    0      0  ...     0   0   \n",
              "2        0    0    0    0    0     0    0     0    0      0  ...     0   0   \n",
              "3        1    0    0    0    0     0    0     0    0      0  ...     0   0   \n",
              "4        0    0    0    0    0     0    0     0    0      0  ...     0   0   \n",
              "\n",
              "   week  well  what  work  yeah  yes  you  your  \n",
              "0     0     0     0     0     0    0    0     0  \n",
              "1     0     0     0     0     0    0    0     0  \n",
              "2     0     0     0     0     0    0    0     0  \n",
              "3     0     0     0     0     0    0    0     0  \n",
              "4     0     0     0     0     0    0    0     0  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "_9t_7puBlp2M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Document Trigram Matrix"
      ]
    },
    {
      "metadata": {
        "id": "T2Kl_6I5lpUY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "36a258f1-f5cf-4b3f-bf3d-dcda94a05d69",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733340785,
          "user_tz": 420,
          "elapsed": 601,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=max_features, ngram_range=(3, 3))\n",
        "vectorizer.fit(corpus)\n",
        "ngram_matrix = vectorizer.transform(corpus)\n",
        "ngram_frequency = sparse_to_dataframe(vectorizer, ngram_matrix)\n",
        "ngram_frequency.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account statement show</th>\n",
              "      <th>admirer looking make</th>\n",
              "      <th>anytime network min</th>\n",
              "      <th>await collection sae</th>\n",
              "      <th>bonus caller prize</th>\n",
              "      <th>call claim code</th>\n",
              "      <th>call customer service</th>\n",
              "      <th>call identifier code</th>\n",
              "      <th>call just per</th>\n",
              "      <th>call land line</th>\n",
              "      <th>...</th>\n",
              "      <th>urgent please call</th>\n",
              "      <th>urgent we trying</th>\n",
              "      <th>urgent your mobile</th>\n",
              "      <th>we trying contact</th>\n",
              "      <th>week nokia tone</th>\n",
              "      <th>week txt nokia</th>\n",
              "      <th>won guaranteed cash</th>\n",
              "      <th>your account statement</th>\n",
              "      <th>your mobile no</th>\n",
              "      <th>your mobile number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   account statement show  admirer looking make  anytime network min  \\\n",
              "0                       0                     0                    0   \n",
              "1                       0                     0                    0   \n",
              "2                       0                     0                    0   \n",
              "3                       0                     0                    0   \n",
              "4                       0                     0                    0   \n",
              "\n",
              "   await collection sae  bonus caller prize  call claim code  \\\n",
              "0                     0                   0                0   \n",
              "1                     0                   0                0   \n",
              "2                     0                   0                0   \n",
              "3                     0                   0                0   \n",
              "4                     0                   0                0   \n",
              "\n",
              "   call customer service  call identifier code  call just per  call land line  \\\n",
              "0                      0                     0              0               0   \n",
              "1                      0                     0              0               0   \n",
              "2                      0                     0              0               0   \n",
              "3                      0                     0              0               0   \n",
              "4                      0                     0              0               0   \n",
              "\n",
              "          ...          urgent please call  urgent we trying  \\\n",
              "0         ...                           0                 0   \n",
              "1         ...                           0                 0   \n",
              "2         ...                           0                 0   \n",
              "3         ...                           0                 0   \n",
              "4         ...                           0                 0   \n",
              "\n",
              "   urgent your mobile  we trying contact  week nokia tone  week txt nokia  \\\n",
              "0                   0                  0                0               0   \n",
              "1                   0                  0                0               0   \n",
              "2                   0                  0                0               0   \n",
              "3                   0                  0                0               0   \n",
              "4                   0                  0                0               0   \n",
              "\n",
              "   won guaranteed cash  your account statement  your mobile no  \\\n",
              "0                    0                       0               0   \n",
              "1                    0                       0               0   \n",
              "2                    0                       0               0   \n",
              "3                    0                       0               0   \n",
              "4                    0                       0               0   \n",
              "\n",
              "   your mobile number  \n",
              "0                   0  \n",
              "1                   0  \n",
              "2                   0  \n",
              "3                   0  \n",
              "4                   0  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "4HFIaOJqluWd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "metadata": {
        "id": "T9_DbOoclx5K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "3dae78d9-2f14-4571-fde6-6660e9f0d791",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528733361423,
          "user_tz": 420,
          "elapsed": 382,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "vectorizer.fit(corpus)\n",
        "tfidf_matrix = vectorizer.transform(corpus)\n",
        "tfidf = sparse_to_dataframe(vectorizer, tfidf_matrix)\n",
        "tfidf.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>already</th>\n",
              "      <th>amp</th>\n",
              "      <th>and</th>\n",
              "      <th>are</th>\n",
              "      <th>ask</th>\n",
              "      <th>back</th>\n",
              "      <th>but</th>\n",
              "      <th>call</th>\n",
              "      <th>can</th>\n",
              "      <th>claim</th>\n",
              "      <th>...</th>\n",
              "      <th>way</th>\n",
              "      <th>we</th>\n",
              "      <th>week</th>\n",
              "      <th>well</th>\n",
              "      <th>what</th>\n",
              "      <th>work</th>\n",
              "      <th>yeah</th>\n",
              "      <th>yes</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.465053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    already  amp  and  are  ask  back  but  call  can  claim  ...   way   we  \\\n",
              "0  0.000000  0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0  0.0   \n",
              "1  0.000000  0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0  0.0   \n",
              "2  0.000000  0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0  0.0   \n",
              "3  0.465053  0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0  0.0   \n",
              "4  0.000000  0.0  0.0  0.0  0.0   0.0  0.0   0.0  0.0    0.0  ...   0.0  0.0   \n",
              "\n",
              "   week  well  what  work  yeah  yes  you  your  \n",
              "0   0.0   0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
              "1   0.0   0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
              "2   0.0   0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
              "3   0.0   0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
              "4   0.0   0.0   0.0   0.0   0.0  0.0  0.0   0.0  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}