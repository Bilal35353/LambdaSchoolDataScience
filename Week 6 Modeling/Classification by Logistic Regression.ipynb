{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification by Logistic Regression",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1eFdE9Ci7R-Oij44ZTM2mfTxZPw50T9gS",
          "timestamp": 1525973739910
        },
        {
          "file_id": "1PfASmGuADCLENb3NCB76H9dtDO-19TPa",
          "timestamp": 1525824426470
        },
        {
          "file_id": "1PgI6GF3i9aNtD7cdDwdemJi9d2TM3zxl",
          "timestamp": 1525300063576
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "6d-s2xCt9GNa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classification by Logistic Regression\n",
        "\n",
        "We've studied data. We've visualized high dimensional spaces projected onto dimensions which maximized the variance of the data. We've shaped and reshaped matrixes to get them ready to feed into a model. Today, we're going to classify our first set of data.\n",
        "\n",
        "## Logistic Regression\n",
        "\n",
        "[sklearn.linear_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "Logistic regression is a machine learning model that, once trained, estimates the probability that an input value `x` meets some \"requirement\", or doesn't. In logistic regression, `x` is a numerical data-matrix, as we are so familiar with, and `y` is a biary label, or class (that is, it is either 0 or 1).\n",
        "\n",
        "\n",
        "## Configuration\n",
        "\n",
        "Maximum likelihood estimation: assuming that:\n",
        "\n",
        "$P(y=1|x) = \\frac{1}{(1 + e^{-(x^Tw)})}$\n",
        "\n",
        "then the parameters that maximize the likelihood function are found through gradient descent updates. \n",
        "\n",
        "For each sample, for each $x_i$:\n",
        "\n",
        "$w_i = w_i + \\alpha(y_i - p)x_i$\n",
        "\n",
        "The first iteration can start with random valies for $w_i$, or they can all begin at $0$.\n",
        "\n",
        "Logistic Regression has at least eight algorithmic solutions, many of which are supported by `sklearn`. Different hyper parameters apply to different algorithms, such as:\n",
        "\n",
        "* learning_rate (alpha)\n",
        "* epochs\n",
        "* starting weights\n",
        "* tolerance for stopping criteria (that is, stop when error < t)\n",
        "\n",
        "### Implementation\n",
        "\n",
        "See [Logistic Regression](http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf)\n",
        "and [A comparison of numerical optimizers for logistic regression](https://tminka.github.io/papers/logreg/minka-logreg.pdf)\n",
        "\n",
        "## Training\n",
        "\n",
        "Before we train a Logistic Regression model, it is important to separate the features and labels into a training and testing set:\n",
        "\n",
        "```\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state=42)\n",
        "```\n",
        "\n",
        "Example code:\n",
        "   \n",
        "    regr = linear_model.LogisticRegression()\n",
        "    regr.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "## Classification\n",
        "\n",
        "Models like Logistic Regression are designed to create predictions based on new values:\n",
        "\n",
        "Example code:\n",
        "    \n",
        "    prediction = regr.predict(x)\n",
        "    \n",
        "However, in research practice, models are used to compare their benchmark performance, typically by measuring their test set accuracy.\n",
        "\n",
        "\n",
        "## Testing / Validation\n",
        "\n",
        "For Linear Regression, we \"tested on our training set\", which is a big no-no in machine learning. On higher-powered ML models it is pretty easy to get 100% accuracy when testing on our training set. When a model is perfectly tuned to a single set of data this is called \"overfitting\", and it specifically doesn't tell us about how the model will perform on any previously unseen data.\n",
        "\n",
        "```\n",
        "# Training accuracy:\n",
        "training_accuracy = np.sum(y_hat_train==y_train)/len(y_hat_train)\n",
        "\n",
        "# Test accuracy:\n",
        "y_hat_test = regr.predict(x_test)\n",
        "test_accuracy = np.sum(y_hat_test==y_test)/len(y_hat_test)\n",
        "`````\n",
        "\n",
        "## Measuring results \n",
        "\n",
        "Many of the metrics used in regression are not relevant or useful for evaluating the performance of classification models.\n",
        "\n",
        "### RMSE\n",
        "\n",
        "Root Mean Squared Error is relevant for regression of scalar values, not classes. RMSE measures the average error of each sample in the same scale as the samples themselves. When compared with the variance of the data, informs the experimenter of the quality of the model. If $RMSE < \\sigma$, that is, the RMSE is less than the standard deviation of the data, then each prediction is high quality, predicting a value close to what it might actually be. The larger the ratio $\\frac{RMSE}{\\sigma}$, the lower-quality the prediction.\n",
        "\n",
        "### MSE\n",
        "\n",
        "Mean squared error is related to variance the same way that RMSE is related to $\\sigma$. Used during error calculation because the relative scale of the error is not relevant, only its minimization. This decreases computation time and frequently makes calculating partial derivatives much easier.\n",
        "\n",
        "### SSE\n",
        "\n",
        "Sum of squared-errors is equal to $n \\times MSE$. SSE is useful in a binary classification problem, as the ratio $\\frac{SSE}{n}$ is the percent error rate. Furthermore, since the labels are binary values, the SSE simply gives the number of misclassified points, or the number of errors $e$. It is not useful in the multi-class classification problem. Accuracy, a common metric used in the evaluation of models is related to the percent error rate, as it is the proportion of points classified correctly.\n",
        "\n",
        "$e = \\sum{(\\hat{y}-y)^2}$\n",
        "\n",
        "$error = \\frac{e}{n}$\n",
        "   \n",
        "$accuracy = 1 - error$\n"
      ]
    },
    {
      "metadata": {
        "id": "Zb4JB-FoRoET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your Assignment\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to identify survivors of the titanic dataset. We've already prepared titanic. Now separate it into features `x` and the label `survived = y`. Using LogisticRegression, train a model to predict `y` from `x`.\n",
        "\n",
        "* Try converting the categorical features in titanic into OneHot features. Can you improve results? [One Hot Features](https://yashuseth.blog/2017/12/14/how-to-one-hot-encode-categorical-variables-of-a-large-dataset-in-python/)\n",
        "* Try creating a few \"feature cross\" columns, where you create a new feature in titanic data that is equal to the product of two other features, ie $x_{new} = x_j \\times x_j$ [Feature Crosses](https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture)"
      ]
    },
    {
      "metadata": {
        "id": "FgT8j7qRHpIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Thinking about your assignment\n",
        "\n",
        "1. __What am I being asked to do?__\n",
        "Perform classification on the Titanic dataset, using its features to predict the binary outcome, `Survived`.\n",
        "\n",
        "\n",
        "2. __What coding steps need to be taken to satisfy the problem?__\n",
        "    * Load and preprocess the data, encoding the categorical features so that they can be fed into a logistic regression model. \n",
        "    * Split the data into training and testing data\n",
        "    * Select features, and engineer some feature crosses.\n",
        "    * Train logistic regression models on different sets of features, comparing their performance on the test set using a metric such as accuracy.\n",
        "\n",
        "3. __What must I do to claim that I have \"completed\" the assignment?__\n",
        "    * Train multiple logistic regression models, and report their accuracy\n",
        "    * Have at least a couple models trained on sets of features which include feature crosses"
      ]
    },
    {
      "metadata": {
        "id": "ggFXuIuwRzYz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Complete assignment here.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from itertools import chain, combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yv8EIGarUL7F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading, Preprocessing and Encoding Data"
      ]
    },
    {
      "metadata": {
        "id": "vFhAUtsHSMoO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "893c9904-99d5-405d-d73c-f5ff3216e7f7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082324842,
          "user_tz": 420,
          "elapsed": 519,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def fill_mixed_median_mode(dataframe, medians=list()):\n",
        "    \"\"\" Fill missing values with median for specified column, otherwise mode\n",
        "    \n",
        "    Args:\n",
        "        dataframe (pandas.core.frame.DataFrame): rows of observations of features\n",
        "        medians (list): columns to fill missing values with median instead of mode\n",
        "        \n",
        "    Returns:\n",
        "        dataframe with no missing values\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    null = dataframe.isnull().any()\n",
        "    null_cols = list(null[null].index)\n",
        "    \n",
        "    fill = pd.Series([data[c].median() if c in medians else data[c].mode()[0]\n",
        "                     for c in null_cols], index=null_cols)\n",
        "    \n",
        "    dataframe[null_cols] = dataframe[null_cols].fillna(fill)\n",
        "    return dataframe\n",
        "\n",
        "data = sns.load_dataset('titanic')\n",
        "data = data.drop(['alive','adult_male','who','class','embark_town', 'deck'], axis=1)\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "data_f = fill_mixed_median_mode(data, ['age', 'fare'])\n",
        "\n",
        "for label in ['embarked','sex', 'alone']:\n",
        "    data_f[label] = LabelEncoder().fit_transform(data_f[label])\n",
        "\n",
        "embarked_one_hot = OneHotEncoder().fit_transform(data_f[['embarked']]).toarray()\n",
        "embarked = pd.DataFrame(embarked_one_hot, \n",
        "                        columns=['Southampton', 'Cherbourg', 'Queenstown'], \n",
        "                        dtype=np.int64)\n",
        "\n",
        "data_f = data_f.reset_index(drop=True)\n",
        "data_enc = data_f.join([embarked])\n",
        "data_enc = data_enc.drop(['embarked'], axis=1)\n",
        "\n",
        "data_enc.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>alone</th>\n",
              "      <th>Southampton</th>\n",
              "      <th>Cherbourg</th>\n",
              "      <th>Queenstown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  pclass  sex   age  sibsp  parch     fare  alone  Southampton  \\\n",
              "0         0       3    1  22.0      1      0   7.2500      0            0   \n",
              "1         1       1    0  38.0      1      0  71.2833      0            1   \n",
              "2         1       3    0  26.0      0      0   7.9250      1            0   \n",
              "3         1       1    0  35.0      1      0  53.1000      0            0   \n",
              "4         0       3    1  35.0      0      0   8.0500      1            0   \n",
              "\n",
              "   Cherbourg  Queenstown  \n",
              "0          0           1  \n",
              "1          0           0  \n",
              "2          0           1  \n",
              "3          0           1  \n",
              "4          0           1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "UqeLwJjYUTLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "metadata": {
        "id": "yvqnCS6UTYgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I will drop one of the one-hot features because it is multicollinear with the other two one-hot features. I chose to only encode `Embarked` with one-hot encodings because the other categorical features have what seems to be a meaningful way to speak of ordering."
      ]
    },
    {
      "metadata": {
        "id": "379L6ZFxUUr-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data_enc.drop(['survived', 'Southampton'], axis=1), \n",
        "    data_enc[['survived']], test_size=0.3, random_state=41\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WNkTyxznUID_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Comparing Models on Different Sets of Features"
      ]
    },
    {
      "metadata": {
        "id": "fLnfIFkWTtDN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def compare_models(feature_sets, x_train, x_test, y_train, y_test, log=100):\n",
        "    models = pd.DataFrame([])\n",
        "    \n",
        "    for ix, features in enumerate(feature_sets):\n",
        "        features = list(features)\n",
        "        if len(features) == 0:\n",
        "            continue\n",
        "        \n",
        "        X_train = x_train[features].values.reshape(-1, len(features))\n",
        "        X_test = x_test[features].values.reshape(-1, len(features))\n",
        "\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train, y_train.values.ravel())\n",
        "        yhat = model.predict(X_test)\n",
        "\n",
        "        sse = np.sum(np.power(yhat-y_test.values.ravel(), 2))\n",
        "        error = sse / yhat.shape[0]\n",
        "        accuracy = 1 - error\n",
        "        \n",
        "        params = model.coef_[0]\n",
        "        intercept, = model.intercept_\n",
        "\n",
        "        summary = pd.Series([features, accuracy, params, intercept], name='')\n",
        "        models = models.append(summary)\n",
        "        \n",
        "        if ix%log == 0 and ix > 0:\n",
        "            print(ix+1, 'feature sets analyzed')\n",
        "            \n",
        "    models.columns = ['features', 'accuracy', 'parameters', 'intercept']\n",
        "    \n",
        "    return models\n",
        "\n",
        "def all_subsets(data_cols):\n",
        "    return chain(*map(lambda x: combinations(data_cols, x), range(0, len(data_cols)+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3Y4GvLwWe0i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c6ebe1ca-6836-4b65-effd-acbb010cfa15",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082332861,
          "user_tz": 420,
          "elapsed": 4251,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "features = list(x_train.columns)\n",
        "feature_sets = all_subsets(features)\n",
        "models = compare_models(feature_sets, x_train, x_test, y_train, y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 feature sets analyzed\n",
            "201 feature sets analyzed\n",
            "301 feature sets analyzed\n",
            "401 feature sets analyzed\n",
            "501 feature sets analyzed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WanJ6UfRX8f2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "62694401-e3b1-4ed2-f806-75f3330dcf91",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082333288,
          "user_tz": 420,
          "elapsed": 355,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "models = models.sort_values(by='accuracy', ascending=False).reset_index(drop=True)\n",
        "models.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>parameters</th>\n",
              "      <th>intercept</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, Cherbourg, Qu...</td>\n",
              "      <td>0.790598</td>\n",
              "      <td>[-0.713067526828976, -2.1712488949161717, -0.0...</td>\n",
              "      <td>3.573687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[pclass, sex, age, sibsp, fare, Queenstown]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.6126145810389865, -2.1245286369749707, -0....</td>\n",
              "      <td>3.107392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[pclass, sex, age, sibsp, Cherbourg]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.7425339391211495, -2.1527058397727052, -0....</td>\n",
              "      <td>3.426987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[pclass, sex, age, sibsp, Queenstown]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.7372057184424117, -2.136016184409732, -0.0...</td>\n",
              "      <td>3.526239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, fare, Queenst...</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.5916539450359095, -2.1697502925803436, -0....</td>\n",
              "      <td>3.093395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch]</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>[-0.745857385003808, -2.1774318980909246, -0.0...</td>\n",
              "      <td>3.471734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, fare]</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>[-0.5944809017755814, -2.182362329972832, -0.0...</td>\n",
              "      <td>3.028571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, Cherbourg]</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>[-0.7399297988257098, -2.183256703513817, -0.0...</td>\n",
              "      <td>3.467405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, Queenstown]</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>[-0.7357644101484302, -2.158429265185262, -0.0...</td>\n",
              "      <td>3.550321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, fare, alone]</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>[-0.5322160040312065, -2.1146204335890126, -0....</td>\n",
              "      <td>3.299278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            features  accuracy  \\\n",
              "0  [pclass, sex, age, sibsp, parch, Cherbourg, Qu...  0.790598   \n",
              "1        [pclass, sex, age, sibsp, fare, Queenstown]  0.786325   \n",
              "2               [pclass, sex, age, sibsp, Cherbourg]  0.786325   \n",
              "3              [pclass, sex, age, sibsp, Queenstown]  0.786325   \n",
              "4  [pclass, sex, age, sibsp, parch, fare, Queenst...  0.786325   \n",
              "5                   [pclass, sex, age, sibsp, parch]  0.782051   \n",
              "6             [pclass, sex, age, sibsp, parch, fare]  0.782051   \n",
              "7        [pclass, sex, age, sibsp, parch, Cherbourg]  0.782051   \n",
              "8       [pclass, sex, age, sibsp, parch, Queenstown]  0.782051   \n",
              "9      [pclass, sex, age, sibsp, parch, fare, alone]  0.782051   \n",
              "\n",
              "                                          parameters  intercept  \n",
              "0  [-0.713067526828976, -2.1712488949161717, -0.0...   3.573687  \n",
              "1  [-0.6126145810389865, -2.1245286369749707, -0....   3.107392  \n",
              "2  [-0.7425339391211495, -2.1527058397727052, -0....   3.426987  \n",
              "3  [-0.7372057184424117, -2.136016184409732, -0.0...   3.526239  \n",
              "4  [-0.5916539450359095, -2.1697502925803436, -0....   3.093395  \n",
              "5  [-0.745857385003808, -2.1774318980909246, -0.0...   3.471734  \n",
              "6  [-0.5944809017755814, -2.182362329972832, -0.0...   3.028571  \n",
              "7  [-0.7399297988257098, -2.183256703513817, -0.0...   3.467405  \n",
              "8  [-0.7357644101484302, -2.158429265185262, -0.0...   3.550321  \n",
              "9  [-0.5322160040312065, -2.1146204335890126, -0....   3.299278  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "iQIaAKTAYsXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It seems the models with the highest accuracy on the test set make use of many features and have accuracies of nearly 80%.\n",
        "\n",
        "If we were performing multiple iterations of model selection, feature selection and parameter tuning, then it would be advised to split the data into training, testing and __validation__ sets, where the validation sets would be used for the model selection. This would prevent the chosen model from being biased in favor of the test data.\n",
        "\n",
        "However, since we are not doing this, and are simply comparing the accuracy of out-of-the-box logistic regression models on different sets of features, it is fine to use only a train-test split."
      ]
    },
    {
      "metadata": {
        "id": "aZVeYb5sZaG-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Crosses"
      ]
    },
    {
      "metadata": {
        "id": "Mc8GZ4TnaJAp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I will make new features which are all the crosses of two features. For the purposes of this assignment, I will not consider higher-degree feature crosses. According to the `sklearn` documentation, \"high degrees can cause overfitting.\"\n",
        "\n",
        "Also, I will remove the feature crosses between my one-hot dummy variables which encode the same feature.\n",
        "\n",
        "[`PolynomialFeatures`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) from `sklearn` can produce feature crosses quite easily. By default, it also includes squared individual features. I will include these. Overall, I expect 54 features before removing the redundant one-hot crosses. This is because I will have 9 original features, 9 squared features, and $9C2$ or 36 feature crosses."
      ]
    },
    {
      "metadata": {
        "id": "8g3fCcZqbj7-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3955b6f5-c98e-436d-fbb6-19cc0ffe9375",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082333902,
          "user_tz": 420,
          "elapsed": 322,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>alone</th>\n",
              "      <th>Cherbourg</th>\n",
              "      <th>Queenstown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>247.5208</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pclass  sex   age  sibsp  parch      fare  alone  Cherbourg  Queenstown\n",
              "446       1    0  25.0      1      2  151.5500      0          0           1\n",
              "281       1    0  50.0      0      1  247.5208      0          0           0\n",
              "536       1    1  35.0      0      0   26.5500      1          0           0\n",
              "646       1    0  29.0      0      0  211.3375      1          0           1\n",
              "224       2    1  19.0      0      0   10.5000      1          0           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "u-iLWqEtZYlc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b65c22b4-9c96-4e13-d352-9e9bafa50658",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082335738,
          "user_tz": 420,
          "elapsed": 1012,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(2)\n",
        "poly.fit(x_train)\n",
        "\n",
        "cols = poly.get_feature_names(list(x_train.columns))\n",
        "cross_train = poly.transform(x_train)\n",
        "len(cols)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "IG88X9RFdG02",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It seems there is one more feature than expected. I will print the feature names determined by the function to see if there is an index feature included."
      ]
    },
    {
      "metadata": {
        "id": "ZwluUntmdN1y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6210914e-6be7-4b82-b243-e1d280a01b0d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082336710,
          "user_tz": 420,
          "elapsed": 449,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cols[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1',\n",
              " 'pclass',\n",
              " 'sex',\n",
              " 'age',\n",
              " 'sibsp',\n",
              " 'parch',\n",
              " 'fare',\n",
              " 'alone',\n",
              " 'Cherbourg',\n",
              " 'Queenstown']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "PUjKT0FddUH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first feature name is not the name of any feature in the original data. I will inspect it to see if it is indeed just an index or a dummy feature, and if so remove it."
      ]
    },
    {
      "metadata": {
        "id": "C4iYWi8dbeJk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "85cd17fe-4fb6-4850-a652-f4ef7520ff77",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082338658,
          "user_tz": 420,
          "elapsed": 610,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_train[:, 0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "MMGXidacdrit",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_train = cross_train[:, 1:]\n",
        "cross_test = poly.fit_transform(x_test)[:, 1:]\n",
        "\n",
        "cross_train = pd.DataFrame(cross_train, columns=cols[1:])\n",
        "cross_test = pd.DataFrame(cross_test, columns=cols[1:])\n",
        "\n",
        "cross_train = cross_train.drop(['Cherbourg Queenstown', 'Cherbourg^2', 'Queenstown^2'], axis=1)\n",
        "cross_test = cross_test.drop(['Cherbourg Queenstown', 'Cherbourg^2', 'Queenstown^2'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UULpsoQXfF8K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "d8e6ea92-eae1-4142-cd37-3a40c4b29108",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082341091,
          "user_tz": 420,
          "elapsed": 720,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>alone</th>\n",
              "      <th>Cherbourg</th>\n",
              "      <th>Queenstown</th>\n",
              "      <th>pclass^2</th>\n",
              "      <th>...</th>\n",
              "      <th>parch alone</th>\n",
              "      <th>parch Cherbourg</th>\n",
              "      <th>parch Queenstown</th>\n",
              "      <th>fare^2</th>\n",
              "      <th>fare alone</th>\n",
              "      <th>fare Cherbourg</th>\n",
              "      <th>fare Queenstown</th>\n",
              "      <th>alone^2</th>\n",
              "      <th>alone Cherbourg</th>\n",
              "      <th>alone Queenstown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22967.402500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>247.5208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61266.546433</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>704.902500</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44663.538906</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.250000</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  sex   age  sibsp  parch      fare  alone  Cherbourg  Queenstown  \\\n",
              "0     1.0  0.0  25.0    1.0    2.0  151.5500    0.0        0.0         1.0   \n",
              "1     1.0  0.0  50.0    0.0    1.0  247.5208    0.0        0.0         0.0   \n",
              "2     1.0  1.0  35.0    0.0    0.0   26.5500    1.0        0.0         0.0   \n",
              "3     1.0  0.0  29.0    0.0    0.0  211.3375    1.0        0.0         1.0   \n",
              "4     2.0  1.0  19.0    0.0    0.0   10.5000    1.0        0.0         1.0   \n",
              "\n",
              "   pclass^2        ...         parch alone  parch Cherbourg  parch Queenstown  \\\n",
              "0       1.0        ...                 0.0              0.0               2.0   \n",
              "1       1.0        ...                 0.0              0.0               0.0   \n",
              "2       1.0        ...                 0.0              0.0               0.0   \n",
              "3       1.0        ...                 0.0              0.0               0.0   \n",
              "4       4.0        ...                 0.0              0.0               0.0   \n",
              "\n",
              "         fare^2  fare alone  fare Cherbourg  fare Queenstown  alone^2  \\\n",
              "0  22967.402500      0.0000             0.0         151.5500      0.0   \n",
              "1  61266.546433      0.0000             0.0           0.0000      0.0   \n",
              "2    704.902500     26.5500             0.0           0.0000      1.0   \n",
              "3  44663.538906    211.3375             0.0         211.3375      1.0   \n",
              "4    110.250000     10.5000             0.0          10.5000      1.0   \n",
              "\n",
              "   alone Cherbourg  alone Queenstown  \n",
              "0              0.0               0.0  \n",
              "1              0.0               0.0  \n",
              "2              0.0               0.0  \n",
              "3              0.0               1.0  \n",
              "4              0.0               1.0  \n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "wg9FH-FofXIk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Comparing Models on Sets of Features Including Feature Crosses"
      ]
    },
    {
      "metadata": {
        "id": "U1cyBzR3jGhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is infeasible to use brute force to compare all possible sets of features. The number of elements in the powerset of a set with 51 elements in it would be $\\sum_{n=1}^{54}54Cn = 2251799813685247$\n",
        "\n",
        "Since the set of features `(pclass, sex, age, sibsp, parch)` obtained reasonably high accuracy, I will consider all sets of features containing these 5 features, plus one feature cross.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gZh2il3zeUq-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ec1e205d-0b4f-48d2-9a88-03a833ed5f68",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082342392,
          "user_tz": 420,
          "elapsed": 559,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "base_features = ['pclass', 'sex', 'age', 'sibsp', 'parch']\n",
        "feature_sets = [base_features + [cross_feature] for cross_feature in cross_train.columns[9:]]\n",
        "\n",
        "feature_sets[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass^2'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass sex'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass age'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass sibsp'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass parch'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass fare'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass alone'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass Cherbourg'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'pclass Queenstown'],\n",
              " ['pclass', 'sex', 'age', 'sibsp', 'parch', 'sex^2']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "u8bAcuU3kSdH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "models = compare_models(feature_sets, cross_train, cross_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-qQTBYmejSO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "66591e2d-f347-4a45-8b04-c315170a8e06",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526082345860,
          "user_tz": 420,
          "elapsed": 802,
          "user": {
            "displayName": "Ray Heberer",
            "photoUrl": "//lh4.googleusercontent.com/-BMlr5I5Dhow/AAAAAAAAAAI/AAAAAAAAABc/XW4PF5A8K2Q/s50-c-k-no/photo.jpg",
            "userId": "116545933704048584401"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "models = models.sort_values(by='accuracy', ascending=False).reset_index(drop=True)\n",
        "models.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>parameters</th>\n",
              "      <th>intercept</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, pclass^2]</td>\n",
              "      <td>0.803419</td>\n",
              "      <td>[0.9074074445670642, -2.220952842244613, -0.02...</td>\n",
              "      <td>2.372148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, sex age]</td>\n",
              "      <td>0.799145</td>\n",
              "      <td>[-0.8189312197026689, -0.6604917196082462, 0.0...</td>\n",
              "      <td>2.840853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, age parch]</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>[-0.7270558227129205, -2.2117800075740544, -0....</td>\n",
              "      <td>3.116795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, age sibsp]</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>[-0.7352323192351139, -2.1483417048369873, -0....</td>\n",
              "      <td>3.614215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, parch^2]</td>\n",
              "      <td>0.790598</td>\n",
              "      <td>[-0.7158197676048329, -2.179679711993146, -0.0...</td>\n",
              "      <td>3.270578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, sex Queenstown]</td>\n",
              "      <td>0.790598</td>\n",
              "      <td>[-0.7422410473492815, -2.0000232910095095, -0....</td>\n",
              "      <td>3.479592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, age fare]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.6002038472195966, -2.173033571588067, -0.0...</td>\n",
              "      <td>3.205745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, pclass age]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.2313549002905987, -2.2342086559381698, 0.0...</td>\n",
              "      <td>2.575101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, sibsp Cherbourg]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.748261845467631, -2.179269153383214, -0.02...</td>\n",
              "      <td>3.477617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[pclass, sex, age, sibsp, parch, pclass fare]</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>[-0.668773250263533, -2.183182073261965, -0.02...</td>\n",
              "      <td>3.144014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            features  accuracy  \\\n",
              "0         [pclass, sex, age, sibsp, parch, pclass^2]  0.803419   \n",
              "1          [pclass, sex, age, sibsp, parch, sex age]  0.799145   \n",
              "2        [pclass, sex, age, sibsp, parch, age parch]  0.794872   \n",
              "3        [pclass, sex, age, sibsp, parch, age sibsp]  0.794872   \n",
              "4          [pclass, sex, age, sibsp, parch, parch^2]  0.790598   \n",
              "5   [pclass, sex, age, sibsp, parch, sex Queenstown]  0.790598   \n",
              "6         [pclass, sex, age, sibsp, parch, age fare]  0.786325   \n",
              "7       [pclass, sex, age, sibsp, parch, pclass age]  0.786325   \n",
              "8  [pclass, sex, age, sibsp, parch, sibsp Cherbourg]  0.786325   \n",
              "9      [pclass, sex, age, sibsp, parch, pclass fare]  0.786325   \n",
              "\n",
              "                                          parameters  intercept  \n",
              "0  [0.9074074445670642, -2.220952842244613, -0.02...   2.372148  \n",
              "1  [-0.8189312197026689, -0.6604917196082462, 0.0...   2.840853  \n",
              "2  [-0.7270558227129205, -2.2117800075740544, -0....   3.116795  \n",
              "3  [-0.7352323192351139, -2.1483417048369873, -0....   3.614215  \n",
              "4  [-0.7158197676048329, -2.179679711993146, -0.0...   3.270578  \n",
              "5  [-0.7422410473492815, -2.0000232910095095, -0....   3.479592  \n",
              "6  [-0.6002038472195966, -2.173033571588067, -0.0...   3.205745  \n",
              "7  [-0.2313549002905987, -2.2342086559381698, 0.0...   2.575101  \n",
              "8  [-0.748261845467631, -2.179269153383214, -0.02...   3.477617  \n",
              "9  [-0.668773250263533, -2.183182073261965, -0.02...   3.144014  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "J30iOZSZlORG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using feature crosses resulted in higher accuracies. This hints at the potential gains that feature engineering can bring about, and there likely exists a even better set of features, potentially including multiple feature crosses, than what was found in this assignment."
      ]
    }
  ]
}